{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab03_sol.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQrVscbXOV+Fg54gU653wI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTqryrUSvRfZ",
        "colab_type": "text"
      },
      "source": [
        "### Package import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTYMxN0btg3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import expit as sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhR4ehhIvWnp",
        "colab_type": "text"
      },
      "source": [
        "### Read in data\n",
        "We have data on the birth weights of 189 babies and demographic characteristics and health indicators for the mothers.  The goal of this study was to identify things that might be associated with a low birth weight, defined here as a birth weight of less than 2.5 Kg.  We will ignore the inferential question and ask whether we can predict low birth weight status based on these features.  The specific variables we have are the age of the mother, mother's weight, mother's race (coded as white, black, or other), mother's smoking status, whether or not the mother has hypertension, whether or not there is a presence of uterine irritability, whether or not the mother had premature labors previously, and the number of physician visits during the first trimester (coded as 0, 1, or 2+).\n",
        "\n",
        "A couple of things to note:\n",
        "\n",
        " * **For today, we have a train/test split but not a validation set.**\n",
        " * **I have already standardized the features and transposed everything below so that observations are in columns.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO13yiHItqCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8d684031-5498-4d41-841c-dfea634eae40"
      },
      "source": [
        "birthwt = pd.read_csv(\"http://www.evanlray.com/data/mass/birthwt.csv\")\n",
        "\n",
        "lgl_cols = ['smoke', 'ht', 'ui', 'ptd']\n",
        "birthwt[lgl_cols] = birthwt[lgl_cols].astype('float')\n",
        "birthwt = pd.get_dummies(birthwt, drop_first = True)\n",
        "birthwt.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>low</th>\n",
              "      <th>age</th>\n",
              "      <th>lwt</th>\n",
              "      <th>smoke</th>\n",
              "      <th>ht</th>\n",
              "      <th>ui</th>\n",
              "      <th>ptd</th>\n",
              "      <th>race_other</th>\n",
              "      <th>race_white</th>\n",
              "      <th>ftv_1</th>\n",
              "      <th>ftv_2+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>105</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>108</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>107</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   low  age  lwt  smoke   ht   ui  ptd  race_other  race_white  ftv_1  ftv_2+\n",
              "0    0   19  182    0.0  0.0  1.0  0.0           0           0      0       0\n",
              "1    0   33  155    0.0  0.0  0.0  0.0           1           0      0       1\n",
              "2    0   20  105    1.0  0.0  0.0  0.0           0           1      1       0\n",
              "3    0   21  108    1.0  0.0  1.0  0.0           0           1      0       1\n",
              "4    0   18  107    1.0  0.0  1.0  0.0           0           1      0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHHQVJ5mtvnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a31490ca-2c25-45b2-b3ef-958a87b38e0e"
      },
      "source": [
        "y = birthwt['low'].to_numpy()\n",
        "#print(\"y = \" + str(y))\n",
        "X = birthwt.drop('low', axis = 1).to_numpy()\n",
        "#print(\"X shape = \" + str(X.shape))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "X_train_mean = np.mean(X_train, axis = 0)\n",
        "X_train_std = np.std(X_train, axis = 0)\n",
        "\n",
        "X_train = X_train - X_train_mean\n",
        "X_train = X_train / X_train_std\n",
        "\n",
        "X_test = X_test - X_train_mean\n",
        "X_test = X_test / X_train_std\n",
        "\n",
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 141)\n",
            "(10, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shsYBkOszVc6",
        "colab_type": "text"
      },
      "source": [
        "### Forward propagation\n",
        "I have defined a function below to do forward propagation.  This is what you saw how to do for logistic regression in Lab 2.\n",
        "\n",
        "Defining a function for this is kindof excessive for a model with only 1 layer, but we will see it is very useful for more complicated models.\n",
        "\n",
        "You don't need to do anything to the code below, just run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7B-b7CazRMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(b, w, X):\n",
        "  '''\n",
        "  Forward propagation for a logistic regression model\n",
        "\n",
        "  Arguments:\n",
        "   - b: bias parameter\n",
        "   - w: column vector of weight parameters\n",
        "   - X: matrix of features of shape (p, m) (features in rows, observations in columns)\n",
        "  \n",
        "  Return:\n",
        "   - A python dictionary with two entries: a and z.  Each is of shape (1, m)\n",
        "  '''\n",
        "  z = b + np.dot(w.T, X)\n",
        "  a = sigmoid(z)\n",
        "\n",
        "  return(\n",
        "    {\n",
        "      'z': z,\n",
        "      'a': a\n",
        "    }\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV75oH-Y0_y8",
        "colab_type": "text"
      },
      "source": [
        "Here's an example of calling the function above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr5ekr6A0_AQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "82522dce-a377-4647-97ea-a9336ce20c68"
      },
      "source": [
        "b = np.array([[0.8]])\n",
        "w = np.array([[0.0, 0.0, 0.7, 1.9, 0.7, 1.3, -0.4, -1.2, -0.4, 0.2]]).T\n",
        "forward_results = forward_prop(b, w, X_train)\n",
        "forward_results['a']\n",
        "# could also look at forward_results['z']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91857908, 0.99950865, 0.22084901, 0.06517141, 0.72870874,\n",
              "        0.4272329 , 0.22084901, 0.4272329 , 0.5434871 , 0.15080971,\n",
              "        0.99907229, 0.57757765, 0.78252006, 0.15080971, 0.22649177,\n",
              "        0.5434871 , 0.22084901, 0.06517141, 0.46140153, 0.9999675 ,\n",
              "        0.5434871 , 0.76158072, 0.06517141, 0.4272329 , 0.06517141,\n",
              "        0.06517141, 0.2516598 , 0.5434871 , 0.89368444, 0.06517141,\n",
              "        0.22084901, 0.46140153, 0.85281862, 0.99219602, 0.99856383,\n",
              "        0.46140153, 0.06517141, 0.46140153, 0.46140153, 0.22084901,\n",
              "        0.99950865, 0.72317217, 0.93956551, 0.15080971, 0.2516598 ,\n",
              "        0.96637472, 0.99943573, 0.99283841, 0.85281862, 0.35130422,\n",
              "        0.89368444, 0.93063469, 0.5434871 , 0.9612609 , 0.15080971,\n",
              "        0.46140153, 0.99554075, 0.15080971, 0.15080971, 0.46140153,\n",
              "        0.22649177, 0.22084901, 0.46140153, 0.97866441, 0.99283841,\n",
              "        0.93956551, 0.46140153, 0.4272329 , 0.4272329 , 0.22649177,\n",
              "        0.57757765, 0.6668176 , 0.06517141, 0.15080971, 0.46140153,\n",
              "        0.46140153, 0.46140153, 0.78252006, 0.4272329 , 0.90242111,\n",
              "        0.99978962, 0.5434871 , 0.76743129, 0.96637472, 0.96637472,\n",
              "        0.78252006, 0.06517141, 0.6668176 , 0.2516598 , 0.22084901,\n",
              "        0.57757765, 0.46140153, 0.98137154, 0.89368444, 0.06517141,\n",
              "        0.22649177, 0.99756238, 0.46140153, 0.92835188, 0.68768218,\n",
              "        0.5434871 , 0.5854859 , 0.99554075, 0.86936199, 0.91857908,\n",
              "        0.86936199, 0.15080971, 0.46140153, 0.15080971, 0.99399551,\n",
              "        0.57757765, 0.46140153, 0.22084901, 0.15080971, 0.68768218,\n",
              "        0.46140153, 0.4272329 , 0.4272329 , 0.06517141, 0.4272329 ,\n",
              "        0.98871829, 0.96637472, 0.57757765, 0.4272329 , 0.86936199,\n",
              "        0.99907229, 0.22084901, 0.06517141, 0.06517141, 0.15080971,\n",
              "        0.15080971, 0.4272329 , 0.46140153, 0.99964639, 0.57757765,\n",
              "        0.85169428, 0.06517141, 0.4272329 , 0.99943573, 0.76158072,\n",
              "        0.97059435]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZx4bEUZ26nR",
        "colab_type": "text"
      },
      "source": [
        "### Backward propagation\n",
        "Fill in the function below with code to find and return the partial derivatives of the logistic regression cost function with respect to b and w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNp-A7sn2NtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_prop(X, y, forward_prop_cache):\n",
        "  '''\n",
        "  Backward propagation for a logistic regression model\n",
        "\n",
        "  Arguments:\n",
        "   - X: array of features of shape (p, m) (features in rows, observations in columns)\n",
        "   - y: array of responses of shape (1, m) (observations in columns)\n",
        "   - forward_prop_cache: dictionary with elements 'z' and 'a' from forward propagation\n",
        "  \n",
        "  Return:\n",
        "   - A python dictionary with two entries: dJdb of shape (1, 1) and dJdw of shape (p, 1).\n",
        "  '''\n",
        "  a = forward_prop_cache['a']\n",
        "  dJdz = a - y # Calculate dJdz\n",
        "  dJdb = np.sum(dJdz) # Calculate dJdb\n",
        "  dJdw = np.dot(X, dJdz.T) # Calculate dJdw\n",
        "  \n",
        "  return(\n",
        "    {\n",
        "      'dJdb': dJdb,\n",
        "      'dJdw': dJdw\n",
        "    }\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds919ABOx36x",
        "colab_type": "text"
      },
      "source": [
        "### Initializing estimation\n",
        "We need starting values for b and w for estimation.  Initialize b and w to arrays of appropriate shape from a normal distribution with standard deviation 0.1.  If you're not sure how to generate values from a normal distribution, check out the numpy tutorial at https://github.com/mhc-stat344ne-s2020/Python_NumPy_foundations/blob/master/Python.ipynb under the \"Creating Arrays\" heading.  To get a standard deviation of 0.1, the easiest thing to do is to generate values from a normal distribution with standard deviation 1 and then multiply by 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4nj85_gtxyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(98409)\n",
        "b = np.random.standard_normal((1, 1)) # Replace None to the left with randomly generated initial values for b\n",
        "w = np.random.standard_normal((X_train.shape[0], 1)) # Replace None to the left with randomly generated initial values for w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnmAnN7R43P6",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent\n",
        "Fill in the missing code in the for loop below to run 10000 iterations of gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBh3zDq4fbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.1\n",
        "for i in range(10000):\n",
        "  forward_prop_cache = forward_prop(b, w, X_train)\n",
        "  gradients = backward_prop(X_train, y_train, forward_prop_cache)\n",
        "  b = b - alpha * gradients['dJdb'] # Calculate the update to b.  You will need to use gradients['dJdb']\n",
        "  w = w - alpha * gradients['dJdw'] # Calculate the update to b.  You will need to use gradients['dJdw']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOcvpXVhCy2R",
        "colab_type": "text"
      },
      "source": [
        "### Test set accuracy\n",
        "Find predictions for the test set and calculate the test set accuracy.  I got an accuracy of about 73%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Mu4LNx53xA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb206ef-6274-464b-e2ac-68897e628793"
      },
      "source": [
        "forward_prop_cache = forward_prop(b, w, X_test) # Call the forward_prop function for X_test\n",
        "a = forward_prop_cache['a'] # Pull out forward_prop_cache['a']\n",
        "y_hat = (a >= 0.5).astype(int) # Obtain predicted values for y as integer type\n",
        "np.mean(y_hat == y_test) # Find your test set classification accuracy"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7291666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4BCet8bVRTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}